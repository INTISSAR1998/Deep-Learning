{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Depp Learning: chap1- Introduction.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"KutIqW_SOVwK"},"source":["<html> <img style=\"float:center; margin: 0px 0px 0px 0px;\" src=\"https://docs.google.com/uc? export=download&id=1oSZlFJKclv51HrDWJ4CFBwD2EUBlryEn\" width=\"220\" align=\"left\"/> </html> \n","\n","\n","\n","<img src='https://docs.google.com/uc?export=download&id=1K_i0WFzMVinuAy_l_x0RPopN5HTRr3jk' align='right' width='350'/>    \n","<figcaption>\n","\n","</figcaption></center>\n","</figure>\n","\n","<h1><center>Chapitre I  </center></h1>\n","<h1><center><b>Introduction au Deep learning </b></center></h1>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wY1zsU4jEjzt"},"source":["<h4>Enseignant: Jaafar CHAAOURI </h4> "]},{"cell_type":"markdown","metadata":{"id":"5TTcl3fbY5qZ"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"uzjvCofkr6Wa"},"source":["## **Introduction**"]},{"cell_type":"markdown","metadata":{"id":"1idYdwBvQSEE"},"source":["**Intelligence artificielle**: domaine de l'informatique qui vise à amener les ordinateurs à atteindre une intelligence de style humain. Il existe de nombreuses approches pour atteindre cet objectif, notamment l'apprentissage automatique (**machine learning**) et l'apprentissage en profondeur (**deep learning**).\n"]},{"cell_type":"markdown","metadata":{"id":"vOTQ20fRRIvJ"},"source":["\n","- Machine Learning: Les systèmes de ML sont entrainés pour effectuer une tâche particulière plutôt que de les programmer explicitement. Ainsi les modèles obtenus apprennent comment combiner des entrées pour formuler des prédictions efficaces sur des données qui n'ont encore jamais été observées.\n","\n","- Réseau de Neurones: Une construction de Machine Learning inspirée du réseau de neurones (cellules nerveuses) du cerveau biologique. Les réseaux de neurones sont un élément fondamental du Deep learning.\n","\n","- Deep Learning: Un sous-domaine du Machine Learning qui utilise des réseaux de neurones multicouches."]},{"cell_type":"markdown","metadata":{"id":"w4p-O2ycKajl"},"source":["La terminologie de base en matière de Machine Learning."]},{"cell_type":"markdown","metadata":{"id":"cCeczwVGKiGN"},"source":["**Étiquettes**"]},{"cell_type":"markdown","metadata":{"id":"z1LO__DbKm8V"},"source":["Une étiquette est le résultat de la prédiction; la variable y dans une régression linéaire simple. Il peut s'agir de l'espèce animale représentée sur une photo, de la signification d'un extrait audio ou de toute autre chose."]},{"cell_type":"markdown","metadata":{"id":"X3E3SvKUK8eU"},"source":["**Caractéristiques**"]},{"cell_type":"markdown","metadata":{"id":"x5kY-hPRLDDt"},"source":["Une caractéristique est une variable d'entrée ; la variable x dans une régression linéaire simple. Un projet de Machine Learning simple peut utiliser une seule caractéristique, tandis qu'un projet plus sophistiqué en utilisera plusieurs millions, spécifiées sous la forme :"]},{"cell_type":"markdown","metadata":{"id":"GizmToOFLw2O"},"source":["\n","\n","> $x_1,x_2,..x_n$\n","\n"," \n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-rPV41dZN_WN"},"source":["Dans l'exemple du détecteur de spam, les caractéristiques peuvent inclure les éléments suivants :\n","\n","- les mots dans le corps de l'e-mail ;\n","- l'adresse de l'expéditeur ;\n","- l'heure à laquelle l'e-mail a été envoyé ;\n","- l'e-mail contient l'expression \"Une astuce étrange\".\n"]},{"cell_type":"markdown","metadata":{"id":"hnfj5idMOLk_"},"source":["**Exemples**"]},{"cell_type":"markdown","metadata":{"id":"YxxGIk8bOOCg"},"source":["Un exemple est une instance de donnée particulière, x. (x est mis en gras pour indiquer qu'il s'agit d'un vecteur.) Les exemples se répartissent dans deux catégories :\n","\n","- Exemples étiquetés\n","- Exemples sans étiquette\n","\n","Un exemple étiqueté comprend une ou plusieurs caractéristiques et l'étiquette. Par exemple :"]},{"cell_type":"markdown","metadata":{"id":"HocZPqlBOcyM"},"source":["labeled examples: { $features, label$ }:$ (x, y)$ "]},{"cell_type":"markdown","metadata":{"id":"10-PNvgAO9-e"},"source":["On utilise des exemples étiquetés pour **entraîner** le modèle. Dans l'exemple du détecteur de spam, les exemples étiquetés désignent les e-mails que les utilisateurs ont explicitement marqués comme \"spam\" ou \"non-spam\".\n"]},{"cell_type":"markdown","metadata":{"id":"ohlgFqLKPWyW"},"source":["Un exemple sans étiquette contient des caractéristiques, mais pas d'étiquette. Par exemple :"]},{"cell_type":"markdown","metadata":{"id":"qOsd8N8OPafm"},"source":["unlabeled examples: {$features, ?$}: $(x, ?)$"]},{"cell_type":"markdown","metadata":{"id":"YwZxRoxCPvqP"},"source":["Une fois le modèle entraîné avec des exemples étiquetés, on l'utilise pour prédire l'étiquette sur des exemples qui en sont dépourvus. Dans l'exemple du détecteur de spam, les exemples sans étiquette sont des nouveaux e-mails qui n'ont pas encore été étiquetés manuellement."]},{"cell_type":"markdown","metadata":{"id":"c4Srr6oPP0ZF"},"source":["**Modèles :**"]},{"cell_type":"markdown","metadata":{"id":"HHxQWNlYP7Ne"},"source":["Un modèle définit la relation entre les caractéristiques et l'étiquette. Par exemple, un modèle de détection de spam peut associer étroitement certaines caractéristiques à étiquette \"spam\". les deux phases de la durée de vie d'un modèle :\n","\n","- **L'apprentissage** consiste à créer ou à **entraîner** le modèle. En d'autres termes, vous présentez au modèle des exemples étiquetés, et vous lui permettez d'apprendre progressivement les relations entre les caractéristiques et l'étiquette.\n","\n","- **L'inférence** consiste à appliquer le modèle entraîné à des exemples sans étiquette. En d'autres termes, vous utilisez le modèle entraîné pour faire des prédictions efficaces (y')."]},{"cell_type":"markdown","metadata":{"id":"eowq8NDsQyTv"},"source":["**Différence entre régression et classification**"]},{"cell_type":"markdown","metadata":{"id":"2PRbLHmXQ3Pe"},"source":["Les modèles de **régression** prédisent des valeurs continues. Ils formulent, par exemple, des prédictions qui répondent à des questions telles que :\n","\n","- Quelle est la valeur d'un logement en Tunisie ?\n","\n","- Quelle est la probabilité qu'un utilisateur clique sur cette annonce ?\n","\n","Les modèles de **classification** prédisent des valeurs discrètes. Ils formulent, par exemple, des prédictions qui répondent à des questions telles que les suivantes :\n","\n","- Un e-mail donné est-il considéré comme du spam ou non ?\n","\n","- Cette image représente-t-elle un chien, un chat ou un hamster ?"]},{"cell_type":"markdown","metadata":{"id":"uIZijBFZRXyY"},"source":["\n","\n","---\n","\n","\n","## **Régression linéaire**"]},{"cell_type":"markdown","metadata":{"id":"PFTEBdmwVxkY"},"source":["La régression linéaire est un algorithme qui va trouver une droite qui se rapproche le plus possible d’un ensemble de points. Les points représentent les données d’entraînement (Training Set).\n","\n","Schématiquement, on veut un résultat comme celui là :"]},{"cell_type":"markdown","metadata":{"id":"tHLM0cEjV_F3"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=1dyPvJzWjEgwQGsGr5tKRSI_F8CLFgTz_' />\n","<figcaption></figcaption></center>\n","</figure>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cpBmnuimWqTW"},"source":["Les points en orange sont les données d’entrée (input data). Ils sont représentés par le couple $(x_{i}, y_{i})$. Les valeurs $x_{i}$ sont les variables prédictives, et $y_{i}$ est la valeur observée (le prix d’une maison par exemple). On cherche à trouver une droite : \n","$F(x) = \\alpha*x + \\beta$  tel que, quelque soit $x_{i}$, on veut que $F(x_{i})\\approx y_{i}$.\n","\n","En d’autres termes, **on veut une droite qui soit le plus proche possible de tous les points de nos données d’apprentissage**."]},{"cell_type":"markdown","metadata":{"id":"thziJomPaKJ5"},"source":["*Format des données* : \n"]},{"cell_type":"markdown","metadata":{"id":"zlkT69BqdQfB"},"source":["Les données d’apprentissage sont au format CSV. Les données sont séparés par des virgules. La première colonne représente la population d’une ville et la deuxième colonne indique le profit d’un camion ambulant dans cette ville.Une valeur négative indique une perte.Le nombre d’enregistrements de nos données d’entrées est 97.\n","\n","NB. Le fichier est disponible avec le support de cours. \n","\n","Pour résoudre ce problème, on va prédire le profit (la variable Y) en fonction de la taille de la population (la variable prédictive X)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wp5RDpsxcAtl"},"source":["### Chargement des diverses librairies utiles pour ce notebook "]},{"cell_type":"code","metadata":{"id":"VtPH8sMVv-tq"},"source":["# chargement de bibliothéques \n","\"\"\"\n","instruction specifique pour utiliser matplotlib dans un notebook \n","quand on utilise les notebooks Jupyter pour utiliser Matplotlib\n","\"\"\"\n","%matplotlib inline  \n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy import stats"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jx6JfUblcAtq"},"source":["### Chargement du jeu de données"]},{"cell_type":"markdown","metadata":{"id":"Zi_RqluLeLCP"},"source":["Tout d’abord, il faudra lire et charger les données contenues dans le fichier CSV. Python propose via sa librairie Pandas des classes et fonctions pour lire divers formats de fichiers dont le CSV."]},{"cell_type":"code","metadata":{"id":"2oheuiBscAtq"},"source":["df = pd.read_csv(\"univariate_linear_regression_dataset.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aQjYiSwTeRyb"},"source":["La fonction read_csv(), renvoie un DataFrame. Il s’agit d’un tableau de deux dimensions contenant, respectivement, la taille de population et les profits effectués. Pour pouvoir utiliser les librairies de régression de Python, il faudra séparer les deux colonnes dans deux variables Python.\n","\n"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"AOuyOxJdcAtu"},"source":["X =  df.iloc[:,0] #selection de la première colonne de notre dataset (indice 0)\n","Y =  df.iloc[:,1] #selection de la première colonne de notre dataset (indice 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"60Jpi9hdeeJd"},"source":["Les variables X et Y sont maintenant de simples tableaux contenant 97 éléments.\n","\n","Note :\n","\n","- La fonction len() permet d’obtenir la taille d’un tableau\n","- La fonction iloc permet de récupérer une donnée par sa position\n","- iloc[0:len(df),0] permettra de récupérer toutes les données de la ligne 0 à la ligne 97 (qui est len(df)) se trouvant à la colonne d’indice 0"]},{"cell_type":"markdown","metadata":{"id":"3UI3GCbEcAtx"},"source":["### Visualisation du jeu de données"]},{"cell_type":"markdown","metadata":{"id":"C0TPNhCZertp"},"source":["Avant de modéliser un problème de Machine Learning, il est souvent utile de comprendre les données. Pour y arriver, on peut les visualiser dans des graphes pour comprendre leur dispersion, déduire les corrélations entre les variables prédictives etc…\n","\n","Parfois, il est impossible de visualiser les données car le nombre de variables prédictives est trop important. Ce n’est pas le cas ici, on ne dispose que de deux variables : la population et les profits.\n","\n","Nous pouvons utiliser un graphe de type nuage de points (Scatter plot) pour visualiser les données :\n","\n"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"GlvwyKKFcAtx","colab":{"base_uri":"https://localhost:8080/","height":266},"executionInfo":{"status":"ok","timestamp":1573207246901,"user_tz":-60,"elapsed":1078,"user":{"displayName":"Jaafar Chaaouri","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA4-opawK4Z_wqlRSPkY1Af9MKQW9Pm0DwTKwnPCQ=s64","userId":"16971688257570499832"}},"outputId":"cd6daf54-c856-4d87-aa9d-897e4374ad48"},"source":["axes = plt.axes()\n","axes.grid()\n","plt.scatter(X,Y)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXIAAAD5CAYAAAA6JL6mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"TpXsnZgKe1MM"},"source":["On voit clairement qu’il y a une corrélation linéaire entre les variables. Et que plus la taille de la population augmente, plus le profit en fait de même.\n"]},{"cell_type":"markdown","metadata":{"id":"9nvdWOP7cAt1"},"source":["### Entrainement d'un modèle de régression linéaire\n"]},{"cell_type":"markdown","metadata":{"id":"fcRToDVccAt2"},"source":["Note : \n","\n","On peut utiliser le module librairie SciPy (Scientific Python) pour implémenter une régression linéaire. Le sous package stats propose la fonction linregress qui calcul une régression à partir d'un jeu de donnée d'entrainement "]},{"cell_type":"code","metadata":{"id":"hTgNIQzucAt3"},"source":["slope, intercept, r_value, p_value, std_err = stats.linregress(X, Y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ee8HgjCVcAt6"},"source":["### Modèle obtenu\n","\n","Le fonction de prédiction pour une régression linéaire univariée est comme suit :\n","\n","\n","\\begin{align}\n","H(x) = intercept + slope * x\n","\\end{align}\n","\n","avec :\n","* $slope$ : représente la \"pente\" de la line de prédiction \n","* $intercept$ : représente le point d'intersection avec l'axe des ordonnées\n","\n","\n","Les coefficients de notre fonction de prédiction ont déjà été calculé et valent : \n"]},{"cell_type":"code","metadata":{"id":"9W_ZsTkccAt7","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1573207287333,"user_tz":-60,"elapsed":1103,"user":{"displayName":"Jaafar Chaaouri","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA4-opawK4Z_wqlRSPkY1Af9MKQW9Pm0DwTKwnPCQ=s64","userId":"16971688257570499832"}},"outputId":"c73a31ed-bbfb-4fee-8530-9fc5fb5b922f"},"source":["slope, intercept"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1.2135472539083585, -4.211504005424089)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"0CKcHTyCcAt-"},"source":["Ainsi notre fonction $H(X)$ se décrit comme suit : \n","\n","\\begin{align}\n","H(X) = -4.211504005424089 + 1.2135472539083585 * X\n","\\end{align}\n","\n","note : \n","* les valeurs de $slope$ et $intercept$ peuvent variées un peu en fonction des valeurs calculées par la fonction linregress et la précision de nombres flottants."]},{"cell_type":"markdown","metadata":{"id":"ytLlqZkncAt_"},"source":["### Ecriture de la fonction de prédiction avec Python\n","\n","Vu qu'on dispose de notre fonction des coefficients de notre fonction de prédiction, on peut l'écrire en python."]},{"cell_type":"code","metadata":{"id":"KzRrGitScAuA"},"source":["# définition de quatre observations\n","def predict(x):\n","    return slope * x + intercept"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eiX1syEWcAuD"},"source":["### Dessiner la fonction de prédiction \n","\n","On peut utiliser la fonction de prédiction qu'on vient de définir pour avoir la valeur prédite par la fonction hypothèse pour chacune des observations de notre jeu d'entrainement. Ainsi on pourra voir visuellement à comment la fonction de prédiction \"approche\" le jeu d'entrainement et qu'elle est par conséquent une bonne fonction de prédiction."]},{"cell_type":"code","metadata":{"id":"aycdQzWccAuE","colab":{"base_uri":"https://localhost:8080/","height":266},"executionInfo":{"status":"ok","timestamp":1573207425689,"user_tz":-60,"elapsed":1192,"user":{"displayName":"Jaafar Chaaouri","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA4-opawK4Z_wqlRSPkY1Af9MKQW9Pm0DwTKwnPCQ=s64","userId":"16971688257570499832"}},"outputId":"3919516a-e4ae-43cf-ad10-08c6081de0fa"},"source":["axes = plt.axes()\n","axes.grid()\n","plt.scatter(X,Y)\n","fitLine = predict(X)\n","plt.plot(X, fitLine, c='r')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXIAAAD5CAYAAAA6JL6mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZGE+y8nBPWLw3gP0AAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"r_TsZWqokmAl"},"source":["En effet, on voit bien que la ligne rouge, approche le plus possible tous les points du jeu de données. "]},{"cell_type":"markdown","metadata":{"id":"Kiu1T8e4cAuH"},"source":["### Prédiction d'une nouvelle observation\n","\n","On voit que pour pour la valeur x = 22.5, la valeur de y pour est environ 25. Utilisons la fonction $predict$ pour trouver une estimation de $H(x = 22.5)$"]},{"cell_type":"code","metadata":{"id":"RgHZsgRScAuI","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1572804576526,"user_tz":-60,"elapsed":701,"user":{"displayName":"Jaafar Chaaouri","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA4-opawK4Z_wqlRSPkY1Af9MKQW9Pm0DwTKwnPCQ=s64","userId":"16971688257570499832"}},"outputId":"05f09712-671e-499c-eda7-261cbe67c52a"},"source":["predict(22.5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["23.093309207513975"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"3JeS21LtcAuL"},"source":["Assez proche ! 22.5 $\\approx$ 23.09"]},{"cell_type":"markdown","metadata":{"id":"lsnId4mJiYYF"},"source":["\n","\n","---\n","\n","\n","## **Apprentissage et perte**"]},{"cell_type":"markdown","metadata":{"id":"-9t2csGrikag"},"source":["Pour un modèle, l'**apprentissage** signifie déterminer les bonnes valeurs pour toutes les pondérations et le biais à partir d'exemples étiquetés. Dans l'apprentissage supervisé, un algorithme de Machine Learning crée un modèle en examinant de nombreux exemples, puis en tentant de trouver un modèle qui minimise la perte. Ce processus est appelé **minimisation du risque empirique**.\n","\n","La perte correspond à la pénalité pour une mauvaise prédiction. Autrement dit, la perte est un nombre qui indique la médiocrité de la prévision du modèle pour un exemple donné. Si la prédiction du modèle est parfaite, la perte est nulle. Sinon, la perte est supérieure à zéro. Le but de l'entraînement d'un modèle est de trouver un ensemble de pondérations et de biais pour lesquels la perte, en moyenne sur tous les exemples, est faible. Par exemple, la figure 3 présente à gauche un modèle dont la perte est élevée, et à droite un modèle dont la perte est faible. À noter concernant cette figure :\n","\n","- Les flèches rouges représentent les pertes.\n","- La ligne bleue représente les prédictions"]},{"cell_type":"markdown","metadata":{"id":"7fg3GDW8i1no"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=1PVHo1AdeJ03uBdbE1ukqD8zxTsVDwVAM' />\n","<figcaption>Figure 3 : Perte élevée dans le modèle de gauche ; perte faible dans le modèle de droite.\n","\n","</figcaption></center>\n","</figure>\n"]},{"cell_type":"markdown","metadata":{"id":"KSfQkkHHjsna"},"source":["Notez que les flèches rouges dans le graphique de gauche sont plus longues que celles de l'autre graphique. Il est clair que la ligne bleue dans le modèle de droite correspond à un modèle prédictif plus performant que celui représenté dans le graphique de gauche.\n","\n","Vous vous demandez peut-être s'il est possible de créer une fonction mathématique (de perte) capable d'agréger les pertes de manière significative.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fAAu3U_Jj1pp"},"source":["Perte quadratique : \n","\n","Les modèles de régression linéaire que nous examinerons ici utilisent une fonction de perte appelée perte quadratique (ou perte L2). Pour un seul exemple, la perte quadratique est :\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jy5UPLQzj7ji"},"source":["\n","\n","```\n","  = the square of the difference between the label and the prediction\n","  = (observation - prediction(x))2\n","  = (y - y')2\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vTIsG7a3kG3z"},"source":["**L'erreur quadratique moyenne** (MSE) correspond à la perte quadratique moyenne pour chaque exemple. Pour calculer l'erreur MSE, il faut additionner toutes les pertes quadratiques de chaque exemple, puis diviser cette somme par le nombre d'exemples :\n","\n","\n","> $ MSE=\\frac{1}{N}\\sum_{x,y}(y-prediction(x))^2 $\n","\n","\n","\n","\n","où :\n","\n"," - $(x,y)$ est un exemple dans lequel :\n"," \n","- $x$ est l'ensemble des caractéristiques (par exemple, température, âge et réussite de l'accouplement) que le modèle utilise pour réaliser des prédictions ;\n"," \n","- $y$ est l'étiquette de l'exemple (par exemple, stridulations/minute).\n"," \n","- $prediction(x)$ est une fonction des pondérations et biais en combinaison avec l'ensemble des caractéristiques $x$.\n","- $D$ est un ensemble de données contenant de nombreux exemples étiquetés, qui sont des paires $(x,y)$.\n","-$N$ est le nombre d'exemples dans $D$.\n","\n","Bien que l'erreur MSE soit couramment utilisée dans le Machine Learning, ce n'est ni la seule fonction de perte pratique, ni la meilleure fonction de perte pour toutes les circonstances.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ikf1UVH-nGzz"},"source":["\n","\n","---\n","\n","\n","### **Réduction de la perte : une approche itérative**"]},{"cell_type":"markdown","metadata":{"id":"PyIS3ePonLAZ"},"source":["- Le module précédent a présenté le concept de perte. Dans ce module, vous découvrirez comment un modèle de Machine Learning peut minimiser la perte.\n","\n","- Le schéma suivant illustre le processus itératif de tâtonnement utilisé par les algorithmes de Machine Learning pour l'entraînement d'un modèle.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kBCbC0FcoP1H"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=1bTK5ehaa8XScUwsD25AD_s9tqwUu7IpA'/>\n","<figcaption>Figure 1 : Approche itérative pour l'apprentissage d'un modèle\n","\n","</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"xD_4ikwNojCh"},"source":["Nous utiliserons cette même approche itérative pendant l'intégralité du cours d'initiation au Machine Learning, en détaillant diverses complications, en particulier celles qui se produisent à l'étape symbolisée par le nuage bleu. Les stratégies itératives sont largement utilisées pour le Machine Learning, car elles s'adaptent parfaitement aux ensembles de données de grande taille.\n","\n","\n","Le \"modèle\" accepte une caractéristique ou plus  en entrée, et permet d'obtenir une prédiction (y') en sortie. Simplifions en imaginant le cas d'un modèle acceptant une caractéristique et permettant d'obtenir une prédiction.\n","\n","> $y'= b+w_1*x_1$\n","\n","Quelles valeurs initiales devons-nous attribuer à $w_1$ et à $b$  ? Dans les problèmes de régression linéaire, il s'avère que les valeurs de départ n'ont aucune importance. Nous pourrions les déterminer de façon aléatoire, mais nous utiliserons plutôt ici les valeurs arbitraires suivantes :\n","\n","\n",">-  $b=0$\n",">-  $w_1=0$\n","\n","Imaginons que la première valeur de caractéristique soit égale à 10. En utilisant cette valeur de caractéristique dans la fonction de prédiction, on obtient le résultat suivant :\n","\n","\n","> $y' = 0 + 0(10)$\n","\n","> $y' = 0$\n","\n","La case \"Fonction de calcul de la perte\" dans le schéma correspond à la fonction de perte utilisée par le modèle. Imaginons que nous utilisions la fonction de perte quadratique. La fonction de perte accepte deux valeurs d'entrée :\n","\n","- $y'$ : la prédiction du modèle pour les caractéristiques x\n","- $y$   : l'étiquette correcte correspondant aux caractéristiques x.\n","\n","Nous avons atteint l'étape \"Calcul de la mise à jour des paramètres\" dans le schéma. C'est à cette étape que le système de Machine Learning examine la valeur de la fonction de perte et génère de nouvelles valeurs pour  et $b$ et $w_1$. \n","\n","Pour le moment, partez du principe que cette mystérieuse case verte détermine de nouvelles valeurs, puis que le système de Machine Learning compare à nouveau toutes ces caractéristiques aux étiquettes existantes, attribuant une nouvelle valeur à la fonction de perte, laquelle génère de nouvelles valeurs de paramètres. \n","\n","Ainsi, l'apprentissage poursuit ses itérations jusqu'à ce que l'algorithme identifie les paramètres du modèle présentant la perte la plus basse possible. L'itération se poursuit généralement jusqu'à ce que la perte globale cesse d'évoluer ou n'évolue plus que très lentement. À ce stade, on déclare généralement que le modèle a convergé.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ldp4ACSrCr3X"},"source":["***L'apprentissage d'un modèle de Machine Learning s'effectue à partir d'une valeur initiale de biais et de pondération aléatoire ajustée de façon itérative jusqu'à obtenir les valeurs de pondération et de biais présentant la perte la moins élevée possible.***"]},{"cell_type":"markdown","metadata":{"id":"FWRZCQmpo1Au"},"source":["\n","\n","---\n","\n","\n","### **Réduction de la perte : la descente de gradient**"]},{"cell_type":"markdown","metadata":{"id":"OQ6ITcLlsV3l"},"source":["Le schéma représentant l'approche itérative (figure 1) contenait une étape très allusive intitulée \"Calculer les mises à jour des paramètres\". Remplaçons ce tour de  algorithmique par des informations plus concrètes.\n","\n","Imaginons que nous disposions du temps et des ressources informatiques nécessaires pour calculer la perte correspondant à toutes les valeurs possibles de $w_1$. Pour les types de problèmes de régression examinés jusqu'ici, le tracé représentant la perte rapportée à  sera toujours convexe. En d'autres termes, ce tracé aura toujours la forme d'un bol, comme dans la figure suivante :"]},{"cell_type":"markdown","metadata":{"id":"OTChRjdSBxK_"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=1eFybak0Y7oPs4J4fcXL-dy8kbE8viDu8'/>\n","    \n","<figcaption>Figure 2 : Les problèmes de régression se traduisent par des tracés perte/pondération convexes.\n","\n","</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"bRtZNvGRDkRy"},"source":["- Les problèmes convexes possèdent un minimum unique : leurs courbes ne présentent qu'un point dont la pente est exactement égale à 0. Ce minimum désigne le point de convergence de la fonction de perte.\n","\n","- Il serait inefficace de déterminer le point de convergence en calculant la fonction de perte pour chaque valeur imaginable de $w_1$ pour l'intégralité de l'ensemble de données. Il existe pour cela un meilleur outil, très utilisé pour le Machine Learning, appelé **la descente de gradient.**\n","\n","- La première étape de l'application de la descente de gradient consiste à choisir une valeur de départ pour $w_1$. Cette valeur de départ importe peu. De nombreux algorithmes attribuent à $w_1$ la valeur 0 ou une valeur aléatoire. Comme le montre la figure suivante, nous avons choisi un point légèrement supérieur à 0.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NIF0YCxSnGD7"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=1Id4wurKiX1V9YbJkvjC6DPWyPAkizGno'/>\n","    \n","<figcaption>Figure 3 : Point de départ d'une descente de gradient\n","</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"tstyvKqQEiFN"},"source":["L'algorithme de descente de gradient calcule ensuite le gradient de la courbe de perte au point de départ. En bref, un **gradient** est un vecteur de dérivées partielles indiquant la direction à suivre pour atteindre le minimum recherché. Comme vous pouvez le constater, le gradient de perte est équivalent à la dérivée pour chaque valeur de pondération (comme illustré en figure 3).\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IeYvg7jrEuFW"},"source":["Un gradient étant un vecteur, il présente les deux caractéristiques suivantes :\n","\n","- une direction\n","- une magnitude\n","\n","Le gradient indique toujours la direction de la croissance maximale de la fonction de perte. L'algorithme de descente de gradient fait un pas dans le sens inverse afin de réduire la perte aussi rapidement que possible.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ix40YaevnnmG"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=1Rcnj71-ueVHsHQu6eN9upMBOUU4OSRLb'/>\n","    \n","<figcaption>Figure 4 : La descente de gradient utilise des gradients négatifs.\n","\n","\n","</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"WPCKmjOtE8Tv"},"source":["Pour déterminer le point suivant dans la courbe de la fonction de perte, l'algorithme de descente de gradient ajoute une fraction de la magnitude du gradient au point de départ, comme illustré dans la figure suivante :"]},{"cell_type":"markdown","metadata":{"id":"v4PFaQd2oqkp"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=19IBZNdwNcbJ7frK3-lc5cgmgrEsL9adr'/>\n","    \n","<figcaption>Figure 5 : Un pas de gradient nous positionne au point suivant de la courbe de perte.\n","\n","\n","</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"AsevnR1oFDVp"},"source":["La descente de gradient répète alors ce processus, se rapprochant ainsi progressivement du minimum."]},{"cell_type":"markdown","metadata":{"id":"B3uf-LXbpiX9"},"source":["\n","\n","---\n","\n","\n","### **Réduction de la perte : le taux d'apprentissage**"]},{"cell_type":"markdown","metadata":{"id":"w8A-FTo9prhY"},"source":["Comme nous l'avons vu, un vecteur de gradient comporte à la fois une direction et une magnitude. Les algorithmes de descente de gradient multiplient généralement le gradient par une valeur scalaire appelée **taux d'apprentissage** (ou parfois pas d'apprentissage) pour déterminer le point suivant. Par exemple, si la magnitude du gradient est de 2,5 et que le taux d'apprentissage est de 0,01, alors l'algorithme de descente de gradient sélectionnera le point suivant situé à une distance de 0,025 du point précédent.\n","\n","Les **hyperparamètres** sont les variables pouvant être ajustées par les programmeurs dans les algorithmes de Machine Learning. La plupart des programmeurs spécialisés dans le Machine Learning consacrent une bonne partie de leur temps à ajuster le taux d'apprentissage. Si vous sélectionnez un taux d'apprentissage trop bas, le temps requis pour l'apprentissage sera trop long."]},{"cell_type":"markdown","metadata":{"id":"eYHqOFGXp-7r"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=1URbxw4dn1CKk_sHz2PcB14HL81hvHQiE'/>\n","\n","<figcaption>Figure 6 : Taux d'apprentissage trop bas\n","\n","\n","\n","</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"tDpCXBhzqcRk"},"source":["Dans le cas contraire, si vous fixez un taux d'apprentissage trop élevé, le point suivant rebondira frénétiquement de part et d'autre du minimum recherché, à la manière d'une expérience de mécanique quantique hors de contrôle :"]},{"cell_type":"markdown","metadata":{"id":"rejnyc0vqZGK"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=1PGB3Hii2UhsQ1oIQs2uB9A44rUoji9Py'/>\n","\n","<figcaption>Figure 7 : Taux d'apprentissage trop élevé\n","\n","\n","\n","\n","\n","</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"WZRmAmUGq3ni"},"source":["Il existe un taux d'apprentissage idéal pour chaque problème de régression. Cette valeur dépend de la courbure de la fonction de perte. Si vous savez que le gradient de la fonction de perte est faible, vous pouvez en toute sécurité essayer un taux d'apprentissage plus élevé, ce qui compense le gradient faible et entraîne un pas d'apprentissage plus grand."]},{"cell_type":"markdown","metadata":{"id":"eMgEoZmVq6ri"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=1Zi7k6W9XCc8ktxDERK4BygXNl_j7tXec'/>\n","<figcaption>Figure 8 : Taux d'apprentissage adéquat\n","</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"q0xJohes2x_c"},"source":["### **Réduction de la perte : la descente de gradient stochastique**"]},{"cell_type":"markdown","metadata":{"id":"NBjxExD-slUr"},"source":["Lors d'une descente de gradient, un **lot** représente le nombre total d'exemples utilisés pour calculer le gradient à chaque itération. Jusqu'à présent, nous avons procédé comme si le lot correspondait à l'intégralité de l'ensemble de données. À grande échelle, les ensembles de données contiennent souvent des milliards, voire des centaines de milliards d'exemples. En outre, les ensembles de données de Google comportent souvent un très grand nombre de caractéristiques. Un lot peut donc être gigantesque. Lorsque le lot est très important, la durée des calculs pour une simple itération peut être particulièrement longue.\n","\n","Un ensemble de données important qui comporte des exemples échantillonnés de façon aléatoire contient généralement des données redondantes. De fait, plus la taille d'un lot augmente, plus la probabilité de redondance sera élevée. Un certain niveau de redondance peut être utile pour atténuer les effets du bruit dans les gradients, mais les lots gigantesques présentent rarement une valeur prédictive supérieure à celle des lots de grande taille.\n","\n","Et s'il était possible d'obtenir le gradient souhaité, en moyenne, avec un nombre de calculs nettement inférieur ? Le choix d'exemples aléatoires dans notre ensemble de données nous permet d'estimer une moyenne importante à partir d'une moyenne bien plus modeste (en acceptant une certaine quantité de bruit). La descente de gradient stochastique (SGD) constitue une application radicale de ce principe, car elle n'utilise qu'un exemple (un lot dont la taille est 1) par itération. Si le nombre d'itérations est assez important, la SGD fonctionne, tout en générant beaucoup de bruit. Le terme \"stochastique\" signifie que l'exemple constituant chaque lot est sélectionné de façon aléatoire.\n","\n","**La descente de gradient stochastique (SGD**) par mini-lots (SGD par mini-lots) offre un compromis entre l'itération des lots entiers et la SGD. Un mini-lot comprend généralement entre 10 et 1 000 exemples sélectionnés aléatoirement. La SGD par mini-lots limite la quantité de bruit propre aux SGD tout en restant plus efficace que le traitement de lots entiers.\n","\n","Nous avons appliqué la descente de gradient à une caractéristique unique. Naturellement, la descente de gradient fonctionne également sur des ensembles de caractéristiques comportant des caractéristiques multiples."]},{"cell_type":"markdown","metadata":{"id":"897sQc1P3gqG"},"source":["## **Les réseaux de neurones :**"]},{"cell_type":"markdown","metadata":{"id":"WZXevB075qvG"},"source":["Le problème de classification suivant était non linéaire :"]},{"cell_type":"markdown","metadata":{"id":"f-K3nkN_7N4t"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=1B8mtl0vnPDUtTVZs2gETzmSxjbxW5yH6' /> \n","<figcaption>\n","Figure 1 : Problème de classification non linéaire.\n","</figcaption></center>\n","</figure>\n"]},{"cell_type":"markdown","metadata":{"id":"regMHZbZ8q3i"},"source":["\"Non linéaire\" signifie qu'il n'est pas possible de prédire avec exactitude une étiquette avec un modèle de la forme\n","\n","\n","\n","> $b+w_1x_1+w_2x_2$\n","\n","\n","\n","Autrement dit, la \"surface de décision\" n'est pas une droite. \n","\n","Voyons à présent l'ensemble de données suivant :\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8B9sxqZk8BDX"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=1k-eivOGup97I2zgrcS9ZEBs7qFb_2vai' />\n","<figcaption>\n","Figure 2 : Problème de classification non linéaire plus complexe.\n","</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"tMDX21fz9bQA"},"source":["L'ensemble de données illustré à la figure 2 ne peut pas être résolu avec un modèle linéaire.\n","\n","Pour voir comment les réseaux de neurones peuvent aider à résoudre les problèmes non linéaires, commençons par représenter un modèle linéaire à l'aide d'un graphique :\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Pv4IKRgL8C0t"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=1Kct9Wba8aIOMvxeDbrCzBw3FLZl9RmRT' />\n","<figcaption>\n","Figure 3 : Représentation graphique d'un modèle linéaire.\n","</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"4db1OYxC90Gu"},"source":["Chaque cercle bleu représente une caractéristique d'entrée, et le cercle vert représente la somme pondérée des entrées.\n","\n","Comment pouvons-nous modifier ce modèle afin d'améliorer sa capacité à traiter les problèmes non linéaires ?\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EWCBS6MS93A3"},"source":["**Couches cachées**\n","\n","Dans le modèle représenté par le graphique suivant, nous avons ajouté une \"couche cachée\" de valeurs intermédiaires. Chaque nœud jaune de la couche cachée est une somme pondérée des valeurs des nœuds d'entrée bleus. La sortie est la somme pondérée des nœuds jaunes.\n"]},{"cell_type":"markdown","metadata":{"id":"u1mYIpdr8E3X"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=1caAzbhVMj4cnmJdQv6E-fn0Z7EALhkyu' width=\"500\" />\n","<figcaption>\n","Figure 4 : Représentation graphique d'un modèle à deux couches.\n","\n","</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"zL5Dpwpq-khD"},"source":["Ce modèle est-il linéaire ? Oui. La sortie est une combinaison linéaire des entrées.\n","\n","Dans le modèle représenté par le graphique suivant, nous avons ajouté une deuxième couche cachée de sommes pondérées.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qAWGlgD-8FRl"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=18DaUb5fDaX-JdiM2MR9-z0iy93ADx-Wq' width=\"500\" />\n","<figcaption>\n","Figure 5 : Représentation graphique d'un modèle à trois couches.\n","</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"3bcBIOcc-5_c"},"source":["Ce modèle est-il toujours linéaire ? Oui. Lorsque la sortie est exprimée comme une fonction de l'entrée, puis simplifiée, vous obtenez simplement une autre somme pondérée des entrées. Cette somme ne modélisera pas efficacement le problème non linéaire de la figure 2.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"r0KTmuW0-8aa"},"source":["**Fonctions d'activation**"]},{"cell_type":"markdown","metadata":{"id":"S73qEVlY8Fje"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=137Mn8yX7ByhFgfTqEL49Zrysm6rwsQGr' width=\"1000\"/>\n","    \n","<figcaption>\n","Figure 6 : Représentation graphique d'un modèle à trois couches avec fonction d'activation.\n","</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"hcpWyC76_3GE"},"source":["Maintenant que nous avons ajouté une fonction d'activation, l'impact de l'ajout de couches est plus important. En empilant des non-linéarités, nous pouvons modéliser des relations très complexes entre les entrées et les sorties prévues. Pour résumer, chaque couche apprend une fonction plus complexe, d'un niveau supérieur, des entrées brutes."]},{"cell_type":"markdown","metadata":{"id":"UnTfr0fi_5ft"},"source":["**Fonctions d'activation courantes**"]},{"cell_type":"markdown","metadata":{"id":"ngMQVMCN_-Xl"},"source":["La fonction d'activation sigmoïde suivante convertit la somme pondérée en une valeur comprise entre 0 et 1.\n",">$F(x)=\\frac{1}{1+e^x}$\n"]},{"cell_type":"markdown","metadata":{"id":"Ps8biJlnBRFA"},"source":["Voici sa représentation graphique :"]},{"cell_type":"markdown","metadata":{"id":"FdlegwJ48Ftn"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=1QqzXdqE_g37FooylM5gHeVlg_8AR5AA3' width=\"450\" />\n","    \n","<figcaption>\n","Figure 7 : Fonction d'activation sigmoïde.\n","</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"xAs2GcxIB0UW"},"source":["La fonction d'activation d'unité de rectification linéaire (ou ReLU) est souvent un peu plus efficace qu'une fonction lisse de type sigmoïde, tout en étant bien plus simple à calculer.\n","\n","\n","\n","> $F(x)= max(0,x)$\n","\n","\n","\n","La supériorité de la fonction ReLU repose sur des conclusions empiriques, sans doute du fait que la fonction ReLU présente une plage de réponse plus utile. La réponse de la fonction sigmoïde est rapidement défaillante de chaque côté.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0ZxXVEyF8F3H"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=1HXLhIYMR6jm5CALeAqDzLU2QhnsfKENw' />\n","<figcaption>\n","    Figure 8 : Fonction d'activation ReLU.\n","\n","</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"xcfkvv5cChvf"},"source":["En fait, toute fonction mathématique peut être utilisée comme fonction d'activation. Supposons que représente notre fonction d'activation (ReLU, sigmoïde ou autre). La valeur d'un nœud dans le réseau est alors donnée par la formule suivante :\n","\n","\n","\n","> $\\sigma (w.x+b)$\n","\n","\n","\n","TensorFlow fournit une aide prête à l'emploi pour une large gamme de fonctions d'activation. Cela étant dit, nous recommandons quand même de commencer par la fonction ReLU.\n","\n","Résumé\n","Notre modèle possède à présent tous les composants standards de ce que l'on appelle généralement un \"réseau de neurones\" :\n","\n","- Un ensemble de nœuds, semblables à des neurones, organisés en couche.\n","- Un ensemble de pondérations, représentant les connexions entre chaque couche du réseau de neurones et la couche inférieure. Cette couche inférieure peut être une autre couche de réseau de neurones ou un autre type de couche.\n","- Un ensemble de biais, un par nœud.\n","- Une fonction d'activation qui transforme la sortie de chaque nœud d'une couche. Différentes couches peuvent avoir différentes fonctions d'activation."]},{"cell_type":"markdown","metadata":{"id":"pYyL4i_eEBqt"},"source":["\n","\n","---\n","\n","\n","### Entraîner les réseaux de neurones : bonnes pratiques"]},{"cell_type":"markdown","metadata":{"id":"x5DqBo158GH5"},"source":["Cette section explique les problèmes possibles de la rétropropagation, ainsi que la méthode la plus utilisée pour régulariser un réseau de neurones.\n","\n","- Problèmes possibles\n","\n","La rétropropagation peut être à l'origine de plusieurs problèmes courants.\n","\n","- Disparition des gradients\n","\n","Les gradients des couches inférieures (qui sont les plus proches de l'entrée) peuvent devenir extrêmement petits. Dans les réseaux profonds, le calcul de ces gradients peut impliquer le produit de nombreux petits termes.\n","\n","Lorsque les gradients se rapprochent de 0 pour les couches inférieures, ces dernières sont entraînées très lentement, voire pas du tout.\n","\n","La fonction d'activation des unités ReLU permet d'empêcher la disparition des gradients.\n","\n","- Explosion des gradients\n","\n","Si les pondérations d'un réseau sont très importantes, les gradients des couches inférieures impliquent le produit de nombreux termes de grande taille. Dans ce cas, les gradients peuvent exploser. Autrement dit, ils sont trop grands pour que la convergence fonctionne.\n","\n","La normalisation de lot, tout comme la réduction du taux d'apprentissage, peut empêcher l'explosion des gradients.\n","\n","- Unités ReLU inactives\n","\n","Lorsque la somme pondérée d'une unité ReLU descend en dessous de 0, l'unité peut se figer. Elle génère alors 0 activation et ne contribue donc pas à la sortie du réseau, tandis que les gradients ne peuvent plus y passer lors de la rétropropagation. En cas d'élimination d'une source de gradients, il se peut même que l'entrée effectuée dans l'unité ReLU ne puisse plus jamais changer suffisamment pour que la somme pondérée repasse au-dessus de 0.\n","\n","La réduction du taux d'apprentissage peut empêcher les unités ReLU de devenir inactives.\n","\n","- Régularisation par abandon\n","\n","Une autre forme de régularisation, appelée abandon, est utile pour les réseaux de neurones. Cette méthode \"abandonne\" de manière aléatoire des activations d'unités dans un réseau pour un pas de gradient unique. Plus il y a d'abandons, plus la régularisation est poussée :\n","\n","0.0 = pas de régularisation par abandon.\n","1.0 = abandon total (le modèle n'apprend rien).\n","Les valeurs comprises entre 0.0 et 1.0 sont plus efficaces."]},{"cell_type":"markdown","metadata":{"id":"Tq_t68-i8GPo"},"source":["\n","\n","---\n","\n","\n","### Réseaux de neurones à classes multiples : un contre tous"]},{"cell_type":"markdown","metadata":{"id":"oa84Sg1vEsbb"},"source":["Un contre tous permet d'utiliser la classification binaire. Étant donné un problème de classification avec N solutions possibles, une solution un contre tous consiste en N classifieurs binaires distincts : un classifieur binaire pour chaque résultat possible. Au cours de l'apprentissage, le modèle parcourt une séquence de classifieurs binaires, formant chacun pour répondre à une question de classification distincte. Par exemple, prenons une image représentant un chien. Cinq reconnaissances différentes pourront être formées, dont quatre verront l'image comme un exemple négatif (pas un chien) et une verra l'image comme un exemple positif (un chien). Par exemple :\n","\n","- Cette image représente-t-elle une pomme ? Non.\n","- Cette image représente-t-elle un ours ? Non.\n","- Cette image représente-t-elle des friandises ? Non.\n","- Cette image représente-t-elle un chien ? Oui.\n","- Cette image représente-t-elle un œuf ? Non.\n","\n","Cette approche est relativement raisonnable lorsque nombre total de classes est réduit, mais devient de plus en plus inefficace à mesure que le nombre de classes augmente.\n","\n","Nous pouvons créer un modèle un contre tous considérablement plus efficace avec un réseau de neurones profond, dans lequel chaque nœud de résultat représente une classe différente. La figure suivante suggère cette approche :"]},{"cell_type":"markdown","metadata":{"id":"wD7crXDc8F_s"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=1WMGz-KC_7ttL18hKS9BFsETxuDLYzRWd' width=\"500\" />\n","<figcaption>\n","Figure 1 : Réseau de neurones un contre tous.\n","</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"R-Px1JKWFl-p"},"source":["\n","\n","---\n","\n","\n","**Réseaux de neurones à classes multiples : Softmax**"]},{"cell_type":"markdown","metadata":{"id":"hVEFjv1sFu1F"},"source":["\n","Rappelez-vous que la régression logistique produit une décimale entre 0 et 1. Par exemple, un résultat de régression logistique de 0,8 pour un classificateur d'e-mails suggère que les chances qu'un e-mail soit indésirable sont de 80 %, et les chances qu'il ne soit pas indésirable de 20 %. De façon évidente, la somme des probabilités qu'un e-mail soit indésirable ou non est égale à 1.\n","\n","**Softmax** étend cette idée à un monde à plusieurs classes. C'est-à-dire que Softmax attribue des probabilités décimales à chaque classe d'un problème à plusieurs classes. La somme de ces probabilités décimales doit être égale à 1. Cette contrainte supplémentaire permet de faire converger l'apprentissage plus rapidement qu'il ne le ferait autrement.\n","\n","Par exemple, revenons à l'analyse de l'image de la Figure 1. Softmax pourra produire les probabilités suivantes qu'une image appartienne à une classe spécifique :\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NYY_CskGF5Ku"},"source":["\t\n","\t\n","\n","\n",">Classe | Probabilité\n",">--- | ---\n","> pomme| 0,001 \n","> ours |\t0,04\n","> friandises |\t0,008\n","> chien\t| 0,95\n","> œuf\t| 0,001"]},{"cell_type":"markdown","metadata":{"id":"slPtwKBcGk1H"},"source":["Softmax est mis en œuvre via une couche de réseau de neurones juste avant la couche du résultat. La couche Softmax doit comporter le même nombre de nœuds que la couche du résultat."]},{"cell_type":"markdown","metadata":{"id":"fdKYe4anGoWq"},"source":["<figure>\n","<center>\n","<img src='https://docs.google.com/uc?export=download&id=1WHaJv1U-cX1FvQy6r4y3uMRU89ksfV0v' width=\"500\" />\n","<figcaption>\n","Figure 2 : Une couche Softmax dans un réseau de neurones.\n","</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"yREl3xzIHL2N"},"source":["**Options de Softmax**\n","\n","Prenons les variantes de Softmax suivantes :\n","\n","- Softmax complet est le Softmax dont nous avons parlé, c'est-à-dire le Softmax qui calcule une probabilité pour chaque classe possible.\n","\n","- L'échantillonnage de candidats signifie que Softmax calcule une probabilité pour toutes les étiquettes positives, mais seulement pour un échantillon aléatoire d'étiquettes négatives. Par exemple, si nous souhaitons déterminer si une image d'entrée est un beagle ou un limier, il est inutile de fournir des probabilités pour chaque exemple \"non chien\".\n","\n","Softmax complet est relativement économique lorsque le nombre de classes est petit, mais devient extrêmement coûteux lorsque le nombre de classes augmente. L'échantillonnage de candidats peut améliorer l'efficacité des problèmes qui comportent un grand nombre de classes.\n","\n","**Une étiquette ou plusieurs étiquettes**\n","\n","Softmax suppose que chaque exemple appartient exactement à une classe. Cependant, certains exemples peuvent appartenir simultanément à plusieurs classes. Pour ces exemples :\n","\n","- Vous ne pouvez pas utiliser Softmax.\n","- Vous devez vous appuyer sur les régressions logistiques.\n","\n","Par exemple, supposons que vos exemples sont des images contenant exactement un élément : un fruit. Softmax peut déterminer la probabilité que cet élément soit une poire, une orange, une pomme, etc. Si vos exemples sont des images contenant toute sorte de choses (des saladiers contenant plusieurs types de fruits), alors vous devrez utiliser plusieurs régressions logistiques.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ajWX2V65TGL6"},"source":["## **Atelier de programmation**"]},{"cell_type":"markdown","metadata":{"id":"HezLrgS0TS_S"},"source":["Basic classification: Classify images of clothing\n"]}]}